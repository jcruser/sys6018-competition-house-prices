#KAGGLE HOUSE PRICES COMPETITION
#Team = Competition 1-8
#Elizabeth Homan, eih2nn
#Jenn Cruser, jc4pg
#Boh Young Suh, bs6ea

##### DATA CLEANING AND PREPARATION #####

library(tidyverse) #Load the core tidyverse packages: ggplot2, tibble, tidyr, readr, purrr, and dplyr

#Read in files:
train <- read_csv("train.csv") #Read in the comma separated value data file for training the model
test <- read_csv("test.csv") #Read in the csv data file for testing the model
sample <- read_csv("sample_submission.csv") #Read in the csv data file for sample submission

#Replace NA with "None" for all relevant columns in both training and testing sets
Nones <- c("Alley", "BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", 
           "GarageType", "GarageFinish", "GarageQual", "GarageCond", "PoolQC", "Fence", "MiscFeature", "FireplaceQu")

for(i in 1:length(Nones)) {
  train[,Nones][i][is.na(train[,Nones][i])] = 'None'
}

for(i in 1:length(Nones)) {
  test[,Nones][i][is.na(test[,Nones][i])] = 'None'
}

#Subset to cross validate later
sub <- sample(1:1460,size=730) 
train.2 <- train[sub,]     #Select subset for training
validate <- train[-sub,]  #Set aside subset for validation


#Use factor to adjust the variables that are categorical
factors <- c("MSZoning","Street","LotShape","LandContour","Utilities","LotConfig","LandSlope",
             "Neighborhood","Condition1","Condition2","BldgType","HouseStyle","RoofStyle","RoofMatl",
             "Exterior1st","Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual",
             "BsmtCond","BsmtExposure","BsmtFinType1", "BsmtFinType2","BsmtFinSF2","Heating","HeatingQC","CentralAir",
             "Electrical","KitchenQual","Functional","GarageType","GarageFinish","GarageQual","GarageCond",
             "PavedDrive","SaleType","SaleCondition","Alley","PoolQC", "Fence", "MiscFeature", "FireplaceQu")

train.2[factors] = lapply(train.2[factors], factor)
test[factors] = lapply(test[factors], factor) #Also do this for the test set
validate[factors] = lapply(validate[factors], factor) #Also for the validation set

#Change all columns with integers to the numeric class
train.2[ , (!names(train.2) %in% factors)] = lapply(train.2[ , (!names(train.2) %in% factors)], as.numeric)
test[ , (!names(test) %in% factors)] = lapply(test[ , (!names(test) %in% factors)], as.numeric)
validate[ , (!names(validate) %in% factors)] = lapply(validate[ , (!names(validate) %in% factors)], as.numeric)

sapply(train.2, class) #Check classes to make sure everything worked correctly

#Create mode function
Mode <- function(x, na.rm) {
  xtab <- table(x)
  xmode <- names(which(xtab == max(xtab)))
  if (length(xmode) > 1) xmode <- ">1 mode"
  return(xmode)
}

#Replace all NA values in "factor" columns with the mode of that column
for (var in 1:ncol(train.2)) {  
  if (lapply((train.2[,var]), class)=="factor") {
    train.2[is.na(train.2[,var]),var] <- Mode(train.2[,var], na.rm = TRUE)
  }
}

#Repeat for test set
for (var in 1:ncol(test)) {  
  if (lapply((test[,var]), class)=="factor") {
    test[is.na(test[,var]),var] <- Mode(train.2[,var], na.rm = TRUE)
  }
}

#Repeat for validation set
for (var in 1:ncol(validate)) {  
  if (lapply((validate[,var]), class)=="factor") {
    validate[is.na(validate[,var]),var] <- Mode(train.2[,var], na.rm = TRUE)
  }
}

#Replace all NA values in "numeric" columns with the mean of that column 
#(repeat for test and validation sets)
for (var in 1:ncol(train.2)) {
  if (lapply((train.2[,var]), class)=="numeric") {
    train.2[is.na(train.2[,var]),var] <- sapply(train.2[,var], mean, na.rm=TRUE)
  }
}

for (var in 1:ncol(test)) {
  if (lapply((test[,var]), class)=="numeric") {
    test[is.na(test[,var]),var] <- sapply(train.2[,var], mean, na.rm=TRUE)
  }
}

for (var in 1:ncol(validate)) {
  if (lapply((validate[,var]), class)=="numeric") {
    validate[is.na(validate[,var]),var] <- sapply(train.2[,var], mean, na.rm=TRUE)
  }
}

#Change names of columns that have numbers in them
names(train.2)[names(train.2) == '1stFlrSF'] <- 'FirstFlrSF'
names(train.2)[names(train.2) == '2ndFlrSF'] <- 'SecFlrSF'
names(train.2)[names(train.2) == '3SsnPorch'] <- 'TriSsnPorch'

names(test)[names(test) == '1stFlrSF'] <- 'FirstFlrSF'
names(test)[names(test) == '2ndFlrSF'] <- 'SecFlrSF'
names(test)[names(test) == '3SsnPorch'] <- 'TriSsnPorch'

names(validate)[names(validate) == '1stFlrSF'] <- 'FirstFlrSF'
names(validate)[names(validate) == '2ndFlrSF'] <- 'SecFlrSF'
names(validate)[names(validate) == '3SsnPorch'] <- 'TriSsnPorch'


##### NON-PARAMETRIC APPROACH #####

#Install and load class and caret packages to run knn function 
install.packages("class")
library(class)  
install.packages("caret")
library(caret)

train.3 <- train.2[ , (!names(train.2) %in% factors)] #Select only columns with numeric values
test.2 <- test[ , (!names(test) %in% factors)] #Repeat for test set
validate.2 <- validate[ , (!names(validate) %in% factors)] #Repeat for validation set

trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)
set.seed(22)
knn.fit <- train(SalePrice ~., data = train.3, method = "knn",
                 trControl=trctrl,
                 preProcess = c("center", "scale"),
                 tuneLength = 10)
knn.fit
#k-Nearest Neighbors 
#730 samples
#36 predictor

#Pre-processing: centered (36), scaled (36) 
#Resampling: Cross-Validated (10 fold, repeated 1 times) 
#Summary of sample sizes: 658, 658, 657, 656, 656, 658, ... 
#Resampling results across tuning parameters:

#k   RMSE      Rsquared 
#5  40701.88  0.7586845
#7  40595.15  0.7667168
#9  39956.75  0.7763865
#11  40162.69  0.7801505
#13  40197.83  0.7841858
#15  40091.22  0.7894252
#17  40388.08  0.7894150
#19  40211.36  0.7933000
#21  40339.65  0.7947003
#23  40536.55  0.7950865

#RMSE was used to select the optimal model using  the smallest value.
#The final value used for the model was k = 9.

validate.3 <- subset(validate.2, select = -c(predictions, predictions2, PercentOff1, PercentOff2)) #Create new df without those columns
validate.4 <- subset(validate.2, select = -c(SalePrice))

knn.validate <- predict(knn.fit, newdata = validate.4)
validate.3$knnpredictions <- knn.validate

for (i in 1:nrow(validate.3)) {
  ((abs((validate.3[i,"knnpredictions"])-(validate.3[i,"SalePrice"])))/(validate.3[i,"SalePrice"]))*100 -> validate.3[i,"PercentOff"]
}
AvPercentOff <- mean(validate.3$PercentOff)
AvPercentOff #12.77642 % off of true sale price on average

knn.preds <- predict(knn.fit, newdata = test.2)
knn.preds <- data.frame(predict(knn.fit, newdata = test.2))

colnames(knn.preds)[1] <- "SalePrice"
knn.preds$Id <- Id
knn.preds1 <- knn.preds[,c(2,1)]

#KNN PREDICTIONS -- SCORE = 0.194 on Kaggle (PERSONAL BEST)
write.table(knn.preds1, file = "eih2nn_houses_knn.csv", row.names=F, sep=",") #Write out to a csv
